{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0506f81",
   "metadata": {},
   "source": [
    "# idée\n",
    "=> get score from 1/f, then modulate blended audio using other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4ac9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pydub import AudioSegment\n",
    "from pydub.effects import low_pass_filter\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "# 1. Extract Features\n",
    "def extract_image_features(image_path):\n",
    "    img_bgr = cv2.imread(image_path)\n",
    "    if img_bgr is None:\n",
    "        raise ValueError(f\"Could not load image: {image_path}\")\n",
    "    img_gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n",
    "    img_gray = img_gray.astype(np.float32) / 255.0\n",
    "\n",
    "    # HSV color features\n",
    "    img_hsv = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2HSV)\n",
    "    hsv_mean = np.mean(img_hsv, axis=(0, 1)) / 255.0\n",
    "    hsv_std = np.std(img_hsv, axis=(0, 1)) / 255.0\n",
    "    hue_mean = hsv_mean[0] * (180 / 255) / 180  # Normalize to [0,1]\n",
    "\n",
    "    # Edge density\n",
    "    edges = cv2.Canny((img_gray * 255).astype(np.uint8), 100, 200)\n",
    "    edge_density = np.sum(edges > 0) / edges.size\n",
    "\n",
    "    # 1/f slope\n",
    "    f_transform = np.fft.fft2(img_gray)\n",
    "    f_shift = np.fft.fftshift(f_transform)\n",
    "    power_spectrum = np.abs(f_shift) ** 2\n",
    "    h, w = power_spectrum.shape\n",
    "    y, x = np.indices((h, w))\n",
    "    center = (h // 2, w // 2)\n",
    "    r = np.sqrt((x - center[1]) ** 2 + (y - center[0]) ** 2).astype(np.int32)\n",
    "    radial_sum = np.bincount(r.ravel(), power_spectrum.ravel())\n",
    "    radial_count = np.bincount(r.ravel())\n",
    "    radial_profile = radial_sum / (radial_count + 1e-8)\n",
    "    freqs = np.arange(len(radial_profile))\n",
    "    mask = freqs > 1\n",
    "    if np.any(mask):\n",
    "        log_freqs = np.log(freqs[mask])\n",
    "        log_power = np.log(radial_profile[mask])\n",
    "        slope, _ = np.polyfit(log_freqs, log_power, 1)\n",
    "    else:\n",
    "        slope = 0.0\n",
    "\n",
    "    # Symmetry\n",
    "    left = img_gray[:, :w // 2]\n",
    "    right = np.fliplr(img_gray[:, w - w // 2:])\n",
    "    min_width = min(left.shape[1], right.shape[1])\n",
    "    symmetry_score = ssim(left[:, :min_width], right[:, :min_width])\n",
    "\n",
    "    return {\n",
    "        \"color_hue\": hue_mean,\n",
    "        \"contrast\": np.std(img_gray),\n",
    "        \"edge_density\": edge_density,\n",
    "        \"slope\": slope,\n",
    "        \"symmetry\": symmetry_score\n",
    "    }\n",
    "\n",
    "\n",
    "def blend_audio_from_slope(nature_audio_path, techno_audio_path, slope, output_path, nature_image_path, techno_image_path):\n",
    "    from pydub import AudioSegment\n",
    "    import numpy as np\n",
    "\n",
    "    # 1. Extract slopes from reference images\n",
    "    slope_nature = extract_image_features(nature_image_path)[\"slope\"]\n",
    "    slope_techno = extract_image_features(techno_image_path)[\"slope\"]\n",
    "\n",
    "    # 2. Order slopes\n",
    "    min_slope = min(slope_nature, slope_techno)\n",
    "    max_slope = max(slope_nature, slope_techno)\n",
    "\n",
    "    if slope == slope_nature:\n",
    "        print(\"Slope is equal to the nature reference slope.\")\n",
    "        AudioSegment.from_file(nature_audio_path).export(output_path, format=\"wav\")\n",
    "        return output_path\n",
    "    elif slope == slope_techno:\n",
    "        print(\"Slope is equal to the techno reference slope.\")\n",
    "        AudioSegment.from_file(techno_audio_path).export(output_path, format=\"wav\")\n",
    "        return output_path\n",
    "\n",
    "    # 3. Blend ratio calculation\n",
    "    if slope <= min_slope:\n",
    "        nature_weight, techno_weight = (1.0, 0.0) if slope_nature > slope_techno else (0.0, 1.0)\n",
    "    elif slope >= max_slope:\n",
    "        nature_weight, techno_weight = (1.0, 0.0) if slope_nature < slope_techno else (0.0, 1.0)\n",
    "    else:\n",
    "        blend_ratio = (slope - slope_techno) / (slope_nature - slope_techno)\n",
    "        blend_ratio = np.clip(blend_ratio, 0.0, 1.0)\n",
    "        nature_weight = blend_ratio\n",
    "        techno_weight = 1.0 - blend_ratio\n",
    "\n",
    "    print(f\"Slope: {slope:.3f} | Blend → Nature: {nature_weight:.2f}, Techno: {techno_weight:.2f}\")\n",
    "\n",
    "    # 4. Load, normalize, and align audio\n",
    "    TARGET_FRAME_RATE = 44100 # Standard frame rate for audio processing\n",
    "\n",
    "    audio_nature = AudioSegment.from_file(nature_audio_path).set_channels(1).set_frame_rate(TARGET_FRAME_RATE)\n",
    "    audio_techno = AudioSegment.from_file(techno_audio_path).set_channels(1).set_frame_rate(TARGET_FRAME_RATE)\n",
    "\n",
    "    duration_ms = min(len(audio_nature), len(audio_techno))\n",
    "    print(f\"Aligning audio to {duration_ms} ms\")\n",
    "\n",
    "    audio_nature = audio_nature[:duration_ms]\n",
    "    audio_techno = audio_techno[:duration_ms]\n",
    "\n",
    "    # 5. Convert to numpy arrays\n",
    "    def to_mono_np(audio):\n",
    "        return np.array(audio.get_array_of_samples()).astype(np.float32)\n",
    "\n",
    "    nature_samples = to_mono_np(audio_nature)\n",
    "    techno_samples = to_mono_np(audio_techno)\n",
    "\n",
    "    min_len = min(len(nature_samples), len(techno_samples))\n",
    "    nature_samples = nature_samples[:min_len]\n",
    "    techno_samples = techno_samples[:min_len]\n",
    "\n",
    "    # 6. Blend\n",
    "    blended = nature_weight * nature_samples + techno_weight * techno_samples\n",
    "    blended = np.clip(blended, -32768, 32767).astype(np.int16)\n",
    "\n",
    "    # 7. Export\n",
    "    blended_audio = AudioSegment(\n",
    "        blended.tobytes(),\n",
    "        frame_rate=TARGET_FRAME_RATE,\n",
    "        sample_width=2,\n",
    "        channels=1\n",
    "    )\n",
    "    blended_audio.export(output_path, format=\"wav\")\n",
    "    return output_path\n",
    "\n",
    "\n",
    "# 3. Modulate Audio\n",
    "def modulate_audio_from_color_features(audio_path, features, output_path):\n",
    "    sound = AudioSegment.from_file(audio_path)\n",
    "\n",
    "    # 1. Speed modulation (based on hue)\n",
    "    hue = features.get(\"color_hue\", 0.001)\n",
    "    hue_factor = 10  # Increase impact\n",
    "    speed_factor = 0.8 + hue * hue_factor  # Now can range more widely\n",
    "    new_frame_rate = int(sound.frame_rate * speed_factor)\n",
    "    sound = sound._spawn(sound.raw_data, overrides={\"frame_rate\": new_frame_rate})\n",
    "    # Do not reset with set_frame_rate — keeps the speed effect\n",
    "\n",
    "    # 2. Volume modulation (based on contrast)\n",
    "    contrast = features.get(\"contrast\", 0.5)\n",
    "    contrast_factor = 50  # Was 10, increase to 50 for stronger effect, as first results were too weak\n",
    "    volume_change = (contrast - 0.5) * contrast_factor\n",
    "    sound += volume_change\n",
    "\n",
    "    # 3. Low-pass filter cutoff (based on edge density)\n",
    "    edge_density = features.get(\"edge_density\", 0.5)\n",
    "    cutoff = int(20000 - edge_density * 18000)  # Before: 10k - 8k range\n",
    "    sound = sound.low_pass_filter(cutoff)\n",
    "\n",
    "    sound.export(output_path, format=\"wav\")\n",
    "    return output_path\n",
    "\n",
    "\n",
    "def strongly_modulate_audio_from_features(audio_path, features, output_path):\n",
    "    sound = AudioSegment.from_file(audio_path)\n",
    "\n",
    "    # 1. Strong speed modulation based on hue\n",
    "    hue = features.get(\"color_hue\", 0.001)\n",
    "    hue_factor = 65  # Boosted impact\n",
    "    speed_factor = 0.7 + hue * hue_factor  # More dynamic speed range\n",
    "    new_frame_rate = int(sound.frame_rate * speed_factor)\n",
    "    sound = sound._spawn(sound.raw_data, overrides={\"frame_rate\": new_frame_rate})\n",
    "    # Do NOT reset frame rate, this preserves speed effect\n",
    "\n",
    "    # 2. Strong volume modulation based on contrast\n",
    "    contrast = features.get(\"contrast\", 0.5)\n",
    "    volume_change = (contrast - 0.5) * 70  # Larger volume shifts\n",
    "    sound += volume_change\n",
    "\n",
    "    # 3. Strong low-pass filtering based on edge density\n",
    "    edge_density = features.get(\"edge_density\", 0.5)\n",
    "    cutoff = int(20000 - edge_density * 18000)  # Wider range\n",
    "    sound = low_pass_filter(sound, cutoff)\n",
    "    sound += 40  # Increase overall volume by 40 dB, as it was too low\n",
    "\n",
    "    # Export final sound\n",
    "    sound.export(output_path, format=\"wav\")\n",
    "    return output_path\n",
    "\n",
    "\n",
    "\n",
    "# 4. Run Full Pipeline\n",
    "def process_image_to_sound(image_name, image_pathway, audio_pathway, nature_image, technosphere_image, nature_audio, technosphere_audio):\n",
    "    image_path = os.path.join(image_pathway, image_name + \".jpg\")\n",
    "    features = extract_image_features(image_path)\n",
    "\n",
    "    # Output paths\n",
    "    blended_path = os.path.join(audio_pathway, f\"{image_name}_blended.wav\")\n",
    "    final_path = os.path.join(audio_pathway, f\"{image_name}_final.wav\")\n",
    "\n",
    "    # Blend based on slope\n",
    "    blend_audio_from_slope(\n",
    "    os.path.join(audio_pathway, nature_audio),\n",
    "    os.path.join(audio_pathway, technosphere_audio),\n",
    "    features[\"slope\"],\n",
    "    blended_path,\n",
    "    os.path.join(image_pathway, nature_image + \".jpg\"),\n",
    "    os.path.join(image_pathway, technosphere_image + \".jpg\")\n",
    "    )\n",
    "\n",
    "    # Modulate based on perceptual features\n",
    "    strongly_modulate_audio_from_features(blended_path, features, final_path)\n",
    "    return features, final_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b19f06b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slope: -2.974 | Blend → Nature: 0.36, Techno: 0.64\n",
      "Aligning audio to 12567 ms\n",
      "Processed pref_mila_technosphere.jpg -> Final_audios/pref_mila_technosphere_final.wav\n",
      "Features for pref_mila_technosphere: {'color_hue': 0.0015496181481681726, 'contrast': 0.22279277, 'edge_density': 0.11875569661458334, 'slope': -2.9744744818450077, 'symmetry': 0.35728172065375696}\n",
      "Slope: -3.372 | Blend → Nature: 0.20, Techno: 0.80\n",
      "Aligning audio to 12567 ms\n",
      "Processed photo_18_2025-04-30_17-02-28.jpg -> Final_audios/photo_18_2025-04-30_17-02-28_final.wav\n",
      "Features for photo_18_2025-04-30_17-02-28: {'color_hue': 0.0007906176656274932, 'contrast': 0.24137089, 'edge_density': 0.18087426918621785, 'slope': -3.3718236595466773, 'symmetry': 0.3642963088803445}\n",
      "Slope: -2.656 | Blend → Nature: 0.49, Techno: 0.51\n",
      "Aligning audio to 12567 ms\n",
      "Processed photo_25_2025-04-30_17-02-28.jpg -> Final_audios/photo_25_2025-04-30_17-02-28_final.wav\n",
      "Features for photo_25_2025-04-30_17-02-28: {'color_hue': 0.0009128873835584072, 'contrast': 0.24816889, 'edge_density': 0.14012044270833332, 'slope': -2.656150049537316, 'symmetry': 0.3146555412219137}\n",
      "Slope is equal to the techno reference slope.\n",
      "Processed baseline_tech.jpg -> Final_audios/baseline_tech_final.wav\n",
      "Features for baseline_tech: {'color_hue': 0.0016367101492693254, 'contrast': 0.19806893, 'edge_density': 0.04191704234430148, 'slope': -3.872722719777809, 'symmetry': 0.46985934159982723}\n",
      "Slope: -3.292 | Blend → Nature: 0.24, Techno: 0.76\n",
      "Aligning audio to 15062 ms\n",
      "Processed photo_7_2025-04-30_17-02-28.jpg -> Final_audios/photo_7_2025-04-30_17-02-28_final.wav\n",
      "Features for photo_7_2025-04-30_17-02-28: {'color_hue': 0.0013322438233031456, 'contrast': 0.16812079, 'edge_density': 0.03717382507407875, 'slope': -3.291769322644361, 'symmetry': 0.7006060296447342}\n",
      "Slope: -1.970 | Blend → Nature: 0.77, Techno: 0.23\n",
      "Aligning audio to 15062 ms\n",
      "Processed photo_73_2025-04-30_17-02-28.jpg -> Final_audios/photo_73_2025-04-30_17-02-28_final.wav\n",
      "Features for photo_73_2025-04-30_17-02-28: {'color_hue': 0.0008998537096108869, 'contrast': 0.20348743, 'edge_density': 0.243505859375, 'slope': -1.970479946205507, 'symmetry': 0.30875510943065343}\n",
      "Slope is equal to the nature reference slope.\n",
      "Processed baseline_nat.jpg -> Final_audios/baseline_nat_final.wav\n",
      "Features for baseline_nat: {'color_hue': 0.000554934187471966, 'contrast': 0.22636767, 'edge_density': 0.3623787434895833, 'slope': -1.4078180670904554, 'symmetry': 0.04460079296994398}\n",
      "Slope: -2.818 | Blend → Nature: 0.43, Techno: 0.57\n",
      "Aligning audio to 15584 ms\n",
      "Processed photo_24_2025-04-30_17-02-28.jpg -> Final_audios/photo_24_2025-04-30_17-02-28_final.wav\n",
      "Features for photo_24_2025-04-30_17-02-28: {'color_hue': 0.001077537698341183, 'contrast': 0.23793378, 'edge_density': 0.13268636067708334, 'slope': -2.817587715908378, 'symmetry': 0.2469841748334863}\n",
      "Image with lowest blended score: baseline_tech (score: -3.872722719777809)\n",
      "Image with highest blended score: baseline_nat (score: -1.4078180670904554)\n"
     ]
    }
   ],
   "source": [
    "image_pathway = \"Final_photos/\"\n",
    "audio_pathway = \"Final_audios/\"\n",
    "nature_audio = \"baseline_nat_final.wav\"\n",
    "technosphere_audio = \"baseline_tech_final.wav\"\n",
    "\n",
    "# Process all images in the image_pathway folder\n",
    "lowest_blend_score = None\n",
    "lowest_blend_image = None\n",
    "\n",
    "highest_blend_score = None\n",
    "highest_blend_image = None\n",
    "\n",
    "for fname in os.listdir(image_pathway):\n",
    "    if fname.lower().endswith(\".jpg\"):\n",
    "        image_name = os.path.splitext(fname)[0]\n",
    "        features, output = process_image_to_sound(\n",
    "            image_name=image_name,\n",
    "            image_pathway=image_pathway,\n",
    "            audio_pathway=audio_pathway,\n",
    "            nature_image=\"baseline_nat\",\n",
    "            technosphere_image=\"baseline_tech\",\n",
    "            nature_audio=nature_audio,\n",
    "            technosphere_audio=technosphere_audio\n",
    "        )\n",
    "        print(f\"Processed {fname} -> {output}\")\n",
    "        print(f\"Features for {image_name}: {features}\")\n",
    "\n",
    "        blend_score = features[\"slope\"]\n",
    "        if lowest_blend_score is None or blend_score < lowest_blend_score:\n",
    "            lowest_blend_score = blend_score\n",
    "            lowest_blend_image = image_name\n",
    "        if highest_blend_score is None or blend_score > highest_blend_score:\n",
    "            highest_blend_score = blend_score\n",
    "            highest_blend_image = image_name\n",
    "\n",
    "print(f\"Image with lowest blended score: {lowest_blend_image} (score: {lowest_blend_score})\")\n",
    "print(f\"Image with highest blended score: {highest_blend_image} (score: {highest_blend_score})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6e46b6ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Order of image slopes (lowest to highest):\n",
      "baseline_tech: -3.8727\n",
      "photo_18_2025-04-30_17-02-28: -3.3718\n",
      "photo_7_2025-04-30_17-02-28: -3.2918\n",
      "pref_mila_technosphere: -2.9745\n",
      "photo_24_2025-04-30_17-02-28: -2.8176\n",
      "photo_25_2025-04-30_17-02-28: -2.6562\n",
      "photo_73_2025-04-30_17-02-28: -1.9705\n",
      "baseline_nat: -1.4078\n"
     ]
    }
   ],
   "source": [
    "# Collect all image slopes and names\n",
    "image_slopes = []\n",
    "for fname in os.listdir(image_pathway):\n",
    "    if fname.lower().endswith(\".jpg\"):\n",
    "        image_name = os.path.splitext(fname)[0]\n",
    "        features = extract_image_features(os.path.join(image_pathway, fname))\n",
    "        image_slopes.append((features[\"slope\"], image_name))\n",
    "\n",
    "# Sort by slope\n",
    "image_slopes_sorted = sorted(image_slopes, key=lambda x: x[0])\n",
    "\n",
    "print(\"Order of image slopes (lowest to highest):\")\n",
    "for slope, name in image_slopes_sorted:\n",
    "    print(f\"{name}: {slope:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e35fae7",
   "metadata": {},
   "source": [
    "## Sound Mapping Philosophy\n",
    "\n",
    "Translate these image features into acoustic expressions that support your conceptual axis:\n",
    "\n",
    "| **Feature**             | **Natural Value → Sound Mapping**                                |\n",
    "|-------------------------|-------------------------------------------------------------------|\n",
    "| 1/f Slope ≈ -2          | First audio leans toward nature baseline                          |\n",
    "| Green Hue (low HSV)     | Smooth timbres, analog warmth                                     |\n",
    "| Soft Edges              | Gentle envelopes, low-pass filtering                              |\n",
    "| Low Contrast            | Subtle volume variation, less percussive attack                   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29304be1",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shs_old_python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
